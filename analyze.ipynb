{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed74bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import torch\n",
    "import pickle\n",
    "from Models import single_model as net\n",
    "import numpy as np\n",
    "import Transforms as myTransforms\n",
    "from Dataset import Dataset\n",
    "from parallel import DataParallelModel, DataParallelCriterion\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "from IoUEval import IoUEval\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim.lr_scheduler\n",
    "from torch.nn.parallel import gather\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5cf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1874f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def BCEDiceLoss(inputs, targets):\n",
    "    bce = F.binary_cross_entropy(inputs, targets)\n",
    "    inter = (inputs * targets).sum()\n",
    "    eps = 1e-5\n",
    "    dice = (2 * inter + eps) / (inputs.sum() + targets.sum() + eps)\n",
    "    return bce + 1 - dice\n",
    "\n",
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        if isinstance(target, tuple):\n",
    "            target = target[0]\n",
    "        if inputs.shape[1] == 5:\n",
    "            loss1 = BCEDiceLoss(inputs[:, 0, :, :], target)\n",
    "            loss2 = BCEDiceLoss(inputs[:, 1, :, :], target)\n",
    "            loss3 = BCEDiceLoss(inputs[:, 2, :, :], target)\n",
    "            loss4 = BCEDiceLoss(inputs[:, 3, :, :], target)\n",
    "            loss5 = BCEDiceLoss(inputs[:, 4, :, :], target)\n",
    "            return loss1 + loss2 + loss3 + loss4 + loss5\n",
    "        elif inputs.shape[1] == 1:\n",
    "            #print(inputs.shape)\n",
    "            loss = BCEDiceLoss(inputs[:, 0, :, :], target)\n",
    "            return loss\n",
    "\n",
    "\n",
    "class FLoss(nn.Module):\n",
    "    def __init__(self, beta=0.3, log_like=False):\n",
    "        super(FLoss, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.log_like = log_like\n",
    "\n",
    "    def _compute_loss(self, prediction, target):\n",
    "        EPS = 1e-10\n",
    "        N = prediction.size(0)\n",
    "        TP = (prediction * target).view(N, -1).sum(dim=1)\n",
    "        H = self.beta * target.view(N, -1).sum(dim=1) + prediction.view(N, -1).sum(dim=1)\n",
    "        fmeasure = (1 + self.beta) * TP / (H + EPS)\n",
    "        if self.log_like:\n",
    "            loss = -torch.log(fmeasure)\n",
    "        else:\n",
    "            loss  = 1 - fmeasure\n",
    "        return loss.mean()\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        loss1 = self._compute_loss(inputs[:, 0, :, :], target)\n",
    "        loss2 = self._compute_loss(inputs[:, 1, :, :], target)\n",
    "        loss3 = self._compute_loss(inputs[:, 2, :, :], target)\n",
    "        loss4 = self._compute_loss(inputs[:, 3, :, :], target)\n",
    "        loss5 = self._compute_loss(inputs[:, 4, :, :], target)\n",
    "        return 1.0*loss1 + 1.0*loss2 + 1.0*loss3 + 1.0*loss4 + 1.0*loss5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ab9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val(args, val_loader, model, criterion):\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    sal_eval_val = IoUEval()\n",
    "    epoch_loss = []\n",
    "    total_batches = len(val_loader)\n",
    "    for iter, (input, target) in enumerate(val_loader):\n",
    "        start_time = time.time()\n",
    "\n",
    "        if args.gpu:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "        input_var = torch.autograd.Variable(input)\n",
    "        target_var = torch.autograd.Variable(target).float()\n",
    "\n",
    "        # run the mdoel\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "        #torch.cuda.synchronize()\n",
    "        time_taken = time.time() - start_time\n",
    "\n",
    "        epoch_loss.append(loss.data.item())\n",
    "\n",
    "        # compute the confusion matrix\n",
    "        if args.gpu and torch.cuda.device_count() > 1:\n",
    "            output = gather(output, 0, dim=0)\n",
    "        sal_eval_val.add_batch(output[:, 0, :, :],  target_var)\n",
    "        if iter % 50 == 0 or iter == len(val_loader) - 1:\n",
    "            print('[%d/%d] loss: %.3f time: %.3f' % (iter, total_batches, loss.data.item(), time_taken))\n",
    "\n",
    "    average_epoch_loss_val = sum(epoch_loss) / len(epoch_loss)\n",
    "    IoU, MAE = sal_eval_val.get_metric()\n",
    "    \n",
    "    auc_roc_score = sal_eval_val.get_auc_roc()\n",
    "    \n",
    "    return average_epoch_loss_val, IoU, MAE, auc_roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec50633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_batches 54\n"
     ]
    }
   ],
   "source": [
    "NORMALISE_PARAMS = [np.array([0.406, 0.456, 0.485], dtype=np.float32).reshape((1, 1, 3)), # MEAN\n",
    "                        np.array([0.225, 0.224, 0.229], dtype=np.float32).reshape((1, 1, 3))] # STD\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "data_dir = './data/IDRID'\n",
    "num_workers = 8\n",
    "batch_size = 1\n",
    "\n",
    "# compose the data with transforms\n",
    "trainDataset_main = myTransforms.Compose([\n",
    "    myTransforms.Normalize(*NORMALISE_PARAMS),\n",
    "    myTransforms.Scale(width, height),\n",
    "    myTransforms.RandomCropResize(int(7./224.*width)),\n",
    "    myTransforms.RandomFlip(),\n",
    "    #myTransforms.GaussianNoise(),\n",
    "    myTransforms.ToTensor()\n",
    "])\n",
    "\n",
    "trainDataset_scale1 = myTransforms.Compose([\n",
    "#         myTransforms.Normalize(*NORMALISE_PARAMS),\n",
    "    #myTransforms.Scale(512, 512),\n",
    "    myTransforms.Scale(352, 352),\n",
    "#         myTransforms.RandomCropResize(int(7./224.*args.width)),\n",
    "#         myTransforms.RandomFlip(),\n",
    "    myTransforms.ToTensor()\n",
    "])\n",
    "trainDataset_scale2 = myTransforms.Compose([\n",
    "    myTransforms.Normalize(*NORMALISE_PARAMS),\n",
    "    #myTransforms.Scale(1024, 1024),\n",
    "    myTransforms.Scale(448, 448),\n",
    "    myTransforms.RandomCropResize(int(7./224.*width)),\n",
    "    myTransforms.RandomFlip(),\n",
    "    myTransforms.ToTensor()\n",
    "])\n",
    "\n",
    "valDataset = myTransforms.Compose([\n",
    "    myTransforms.Normalize(*NORMALISE_PARAMS),\n",
    "    myTransforms.Scale(width, height),\n",
    "    myTransforms.ToTensor()\n",
    "])\n",
    "\n",
    "# since we training from scratch, we create data loaders at different scales\n",
    "# so that we can generate more augmented data and prevent the network from overfitting\n",
    "trainLoader_main = torch.utils.data.DataLoader(\n",
    "    Dataset(data_dir, 'train', transform=trainDataset_main),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=False, drop_last=True)\n",
    "\n",
    "valLoader = torch.utils.data.DataLoader(\n",
    "    Dataset(data_dir, 'test', transform=valDataset),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=False, drop_last=True)\n",
    "\n",
    "max_batches = len(trainLoader_main) #+ len(trainLoader_scale1) + len(trainLoader_scale2)\n",
    "print('max_batches {}'.format(max_batches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c50cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d5fa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JCS(\n",
       "  (vgg16): VGG16BN(\n",
       "    (conv1_1): ConvBNReLU(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(64)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv1_2): ConvBNReLU(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(64)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2_1): ConvBNReLU(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(128)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2_2): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(128)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv3_1): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(256)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv3_2): ConvBNReLU(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(256)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv3_3): ConvBNReLU(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(256)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv4_1): ConvBNReLU(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(512)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv4_2): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(512)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv4_3): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(512)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv5_1): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(512)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5_2): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(512)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5_3): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(512)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (gpd): GPD(\n",
       "    (expand_conv): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (reduce_conv): ConvBNReLU(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (end_conv): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (se_block): SEBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=1024, bias=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (dilation_convs): ModuleList(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(9, 9), dilation=(9, 9))\n",
       "    )\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (act2): ReLU(inplace=True)\n",
       "  )\n",
       "  (gpd1): GPD(\n",
       "    (expand_conv): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (reduce_conv): ConvBNReLU(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (end_conv): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (se_block): SEBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=1024, bias=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (dilation_convs): ModuleList(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "    )\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (act2): ReLU(inplace=True)\n",
       "  )\n",
       "  (fpn): ImprovedDecoder(\n",
       "    (inners_a): ModuleList(\n",
       "      (0): ConvBNReLU(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvBNReLU(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvBNReLU(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (inners_b): ModuleList(\n",
       "      (0): ConvBNReLU(\n",
       "        (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvBNReLU(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fuse): ModuleList(\n",
       "      (0): FuseModule(\n",
       "        (se1): SEBlock(\n",
       "          (linear1): Linear(in_features=64, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=64, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv1): ConvBNReLU(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se2): SEBlock(\n",
       "          (linear1): Linear(in_features=96, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=96, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (reduce_conv): ConvBNReLU(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvBNReLU(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): FuseModule(\n",
       "        (se1): SEBlock(\n",
       "          (linear1): Linear(in_features=128, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=128, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv1): ConvBNReLU(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se2): SEBlock(\n",
       "          (linear1): Linear(in_features=192, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=192, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (reduce_conv): ConvBNReLU(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvBNReLU(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): FuseModule(\n",
       "        (se1): SEBlock(\n",
       "          (linear1): Linear(in_features=256, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=256, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv1): ConvBNReLU(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se2): SEBlock(\n",
       "          (linear1): Linear(in_features=384, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=384, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (reduce_conv): ConvBNReLU(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvBNReLU(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): FuseModule(\n",
       "        (se1): SEBlock(\n",
       "          (linear1): Linear(in_features=512, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=512, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv1): ConvBNReLU(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se2): SEBlock(\n",
       "          (linear1): Linear(in_features=768, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=768, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (reduce_conv): ConvBNReLU(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvBNReLU(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): FuseModule(\n",
       "        (se1): SEBlock(\n",
       "          (linear1): Linear(in_features=512, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=512, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv1): ConvBNReLU(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se2): SEBlock(\n",
       "          (linear1): Linear(in_features=768, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=768, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (reduce_conv): ConvBNReLU(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvBNReLU(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cls2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cls3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cls4): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cls5): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = net.JCS()\n",
    "checkpoint_path = './snapshots/18_08/single_pretrained_full_seg_idrid_full_sg_mean_60epoch/checkpoint.pth.tar'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4b5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vals = []\n",
    "sal_eval_val = IoUEval()\n",
    "for iter, (input, target) in enumerate(valLoader):\n",
    "    torch.cuda.empty_cache()\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    input = input.cuda()\n",
    "    target = target.cuda()\n",
    "    input_var = torch.autograd.Variable(input)\n",
    "    target_var = torch.autograd.Variable(target).float()\n",
    "\n",
    "    # run the mdoel\n",
    "    output = model(input_var)\n",
    "    output_vals.append(output[:,0,:,:].detach().cpu().numpy())\n",
    "#     sal_eval_val.add_batch(output[:, 0, :, :],  target_var)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0042401a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vals[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f8c4a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96140996384955"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support, average_precision_score, roc_auc_score\n",
    "import numpy as np\n",
    "data_len = len(valLoader.dataset)\n",
    "tot_auc_pr = 0.0\n",
    "for iter, (input, target) in enumerate(valLoader):\n",
    "    target = target.flatten().numpy()\n",
    "    out = output_vals[iter].flatten()\n",
    "    auc_pr = roc_auc_score(target, out)\n",
    "    tot_auc_pr += auc_pr\n",
    "#     print(\"AUC PR: \", auc_pr)\n",
    "tot_auc_pr/data_len"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
