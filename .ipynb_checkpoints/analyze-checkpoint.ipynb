{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ed74bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import torch\n",
    "import pickle\n",
    "from Models import single_model as net\n",
    "import numpy as np\n",
    "import Transforms as myTransforms\n",
    "from Dataset import Dataset\n",
    "from parallel import DataParallelModel, DataParallelCriterion\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "from IoUEval import IoUEval\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim.lr_scheduler\n",
    "from torch.nn.parallel import gather\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from Dataset import Dataset\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "026a34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os.path as osp\n",
    "import torch.utils.data\n",
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "def scaleRadius(img, scale) :\n",
    "    x=img[int(img.shape[0]/2),:,:].sum(1)\n",
    "#     print(x)\n",
    "    r=(x>x.mean()/10).sum()/2\n",
    "    s=scale * 1.0 / r\n",
    "#     print(r, s)\n",
    "    return cv2.resize(img,(0,0), fx=s, fy=s), r, s\n",
    "\n",
    "def scaleRadius_mask(img, scale, r, s) :\n",
    "    x=img[int(img.shape[0]/2),:,:].sum(1)\n",
    "#     print(x)\n",
    "#     r=(x>x.mean()/10).sum()/2\n",
    "#     s=scale * 1.0 / r\n",
    "#     print(r, s)\n",
    "    img = cv2.resize(img,(0,0), fx=s, fy=s)\n",
    "    img[img > 0] = 255\n",
    "    return img\n",
    "    \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Class to load the dataset\n",
    "    '''\n",
    "    def __init__(self, data_dir, dataset, transform=None):\n",
    "        self.transform = transform\n",
    "        self.img_list = list()\n",
    "        self.msk_list = list()\n",
    "        dataset_name = 'IDRID'\n",
    "        self.data_dir = data_dir\n",
    "        if dataset == 'train':\n",
    "            self.image_df = pd.read_csv('./data/IDRID/idrid_segmentation_file_label_train.csv')\n",
    "        else:\n",
    "            self.image_df = pd.read_csv('./data/IDRID/idrid_segmentation_file_label_test.csv')\n",
    "            \n",
    "        with open(osp.join(data_dir, dataset + '_sg.txt'), 'r') as lines:\n",
    "            for line in lines:\n",
    "                if dataset_name == 'IDRID':\n",
    "                    line_arr = line.split(',')\n",
    "                else:\n",
    "                    line_arr = line.split()\n",
    "                \n",
    "                \n",
    "                self.img_list.append(osp.join(data_dir, line_arr[0].strip()))\n",
    "                self.msk_list.append(osp.join(data_dir, line_arr[1].strip('\\n')))\n",
    "\n",
    "    def __len__(self):\n",
    "#         return len(self.img_list)\n",
    "        return len(self.image_df)\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         if os.path.isfile(self.msk_list[idx]) == False:\n",
    "#             print(\"No file\")\n",
    "        scale = 500\n",
    "        \n",
    "        \n",
    "        img = cv2.imread(os.path.join(self.data_dir, self.image_df['image_path'][idx]))\n",
    "        img, r, s = scaleRadius(img, scale)\n",
    "        img = cv2.addWeighted(img , 4 , cv2.GaussianBlur( img , ( 0 , 0 ) , scale /30) , -4 , 128)\n",
    "        \n",
    "        try:\n",
    "#             mask_1 = cv2.imread(os.path.join(self.data_dir, self.image_df['seg_he_path'][idx]))\n",
    "            mask_1 = Image.open(os.path.join(self.data_dir, self.image_df['seg_he_path'][idx]))\n",
    "            mask_1= np.array(mask_1)\n",
    "        except:\n",
    "#             mask_1 = cv2.imread(os.path.join(self.data_dir, 'blank_mask.tif'))\n",
    "            mask_1 = Image.open(os.path.join(self.data_dir, 'blank_mask.tif'))\n",
    "            mask_1= np.array(mask_1)[:,:,0]\n",
    "        \n",
    "        \n",
    "        try:\n",
    "    #         mask_2 = cv2.imread(os.path.join(self.data_dir, self.image_df['seg_ex_path'][idx]))\n",
    "            mask_2 = Image.open(os.path.join(self.data_dir, self.image_df['seg_ex_path'][idx]))\n",
    "            mask_2= np.array(mask_2)\n",
    "            if mask_2.shape[2] == 4:\n",
    "#                 print(self.image_df['seg_ex_path'][idx])\n",
    "                mask_2= mask_2[:,:,-1]\n",
    "        except:\n",
    "#             mask_2 = cv2.imread(os.path.join(self.data_dir, 'blank_mask.tif'))\n",
    "            mask_2 = Image.open(os.path.join(self.data_dir, 'blank_mask.tif'))\n",
    "            mask_2= np.array(mask_2)[:,:,0]\n",
    "        \n",
    "        try:\n",
    "#             mask_3 = cv2.imread(os.path.join(self.data_dir, self.image_df['seg_se_path'][idx]))\n",
    "            mask_3 = Image.open(os.path.join(self.data_dir, self.image_df['seg_se_path'][idx]))\n",
    "            mask_3= np.array(mask_3)\n",
    "            if mask_3.shape[2] == 3:\n",
    "                mask_3 = mask_3[:,:,2]\n",
    "        \n",
    "        except:\n",
    "#             mask_3 = cv2.imread(os.path.join(self.data_dir, 'blank_mask.tif'))\n",
    "            mask_3 = Image.open(os.path.join(self.data_dir, 'blank_mask.tif'))\n",
    "            mask_3= np.array(mask_3)[:,:,0]\n",
    "#             print(self.image_df['seg_se_path'][idx])\n",
    "\n",
    "        try:\n",
    "    #         mask_4 = cv2.imread(os.path.join(self.data_dir, self.image_df['seg_ma_path'][idx]))\n",
    "            mask_4 = Image.open(os.path.join(self.data_dir, self.image_df['seg_ma_path'][idx]))\n",
    "            mask_4= np.array(mask_4)\n",
    "        except:\n",
    "            mask_4 = Image.open(os.path.join(self.data_dir, 'blank_mask.tif'))\n",
    "            mask_4= np.array(mask_4)[:,:,0]\n",
    "        \n",
    "        print(\"Mask_1 shape: \", mask_1.shape)\n",
    "        print(\"Mask_2 shape: \", mask_2.shape)\n",
    "        print(\"Mask_3 shape: \", mask_3.shape)\n",
    "        print(\"Mask_4 shape: \", mask_4.shape)\n",
    "        print('\\n')\n",
    "\n",
    "        \n",
    "#         mask_1 = scaleRadius_mask(mask_1, scale, r, s)\n",
    "#         mask_2 = scaleRadius_mask(mask_2, scale, r, s)\n",
    "#         mask_3 = scaleRadius_mask(mask_3, scale, r, s)\n",
    "#         mask_4 = scaleRadius_mask(mask_4, scale, r, s)\n",
    "        \n",
    "        # reading and scaling\n",
    "        \n",
    "        masks = [mask_1, mask_2, mask_3, mask_4]\n",
    "        return masks\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image = img, masks = masks)\n",
    "            \n",
    "            transformed['masks'] = [torch.from_numpy(item).unsqueeze(0) for item in transformed['masks']]\n",
    "            label = torch.cat(transformed['masks'])\n",
    "            image = transformed['image']\n",
    "            \n",
    "            return image.float(), label.float()\n",
    "        \n",
    "#         else:\n",
    "            \n",
    "#             return 0 #testing 3d labels\n",
    "\n",
    "\n",
    "    def get_img_info(self, idx):\n",
    "        image = cv2.imread(self.img_list[idx])\n",
    "        return {\"height\": image.shape[0], \"width\": image.shape[1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9df5cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/mnt/sda/haal02-data/IDRID'   \n",
    "a_transform = A.Compose([\n",
    "    A.Resize(width=256, height=256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "b_transform = A.Compose([\n",
    "    A.Resize(width=256, height=256),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "trainLoader_main = torch.utils.data.DataLoader(\n",
    "        Dataset(data_dir, 'train', transform=a_transform),\n",
    "        batch_size=4, shuffle=True, num_workers=4, pin_memory=False, drop_last=True)\n",
    "\n",
    "valLoader = torch.utils.data.DataLoader(\n",
    "        Dataset(data_dir, 'test', transform=b_transform),\n",
    "        batch_size=4, shuffle=False, num_workers=4, pin_memory=False, drop_last=True)\n",
    "\n",
    "train_data = Dataset(data_dir, 'train', transform=a_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7fc254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape: Mask_1 shape:   (2848, 4288)\n",
      "(2848, 4288)Mask_2 shape: \n",
      " (2848, 4288)\n",
      "Mask_3 shape:  Mask_2 shape: (2848, 4288)\n",
      " Mask_4 shape:  (2848, 4288)(2848, 4288)\n",
      "Mask_3 shape:  \n",
      "(2848, 4288)\n",
      "\n",
      "\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  Mask_1 shape: (2848, 4288) \n",
      "(2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)Mask_3 shape: \n",
      " (2848, 4288)\n",
      "Mask_4 shape: Mask_3 shape:  (2848, 4288) \n",
      "(2848, 4288)Mask_4 shape: \n",
      " \n",
      "(2848, 4288)\n",
      "\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_1 shape: Mask_2 shape:   (2848, 4288)(2848, 4288)\n",
      "\n",
      "Mask_3 shape: Mask_2 shape:  (2848, 4288) \n",
      "(2848, 4288)Mask_4 shape: \n",
      " Mask_3 shape: (2848, 4288) \n",
      "(2848, 4288)\n",
      "\n",
      "\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_2 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_3 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_4 shape:  torch.Size([4, 2848, 4288])\n",
      "\n",
      "\n",
      "Mask_1 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_2 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_3 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_4 shape:  torch.Size([4, 2848, 4288])\n",
      "\n",
      "\n",
      "Mask_1 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_2 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_3 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_4 shape:  torch.Size([4, 2848, 4288])\n",
      "\n",
      "\n",
      "Mask_1 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_2 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_3 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_4 shape:  torch.Size([4, 2848, 4288])\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  (2848, 4288)\n",
      "Mask_2 shape:  (2848, 4288)\n",
      "Mask_3 shape:  (2848, 4288)\n",
      "Mask_4 shape:  (2848, 4288)\n",
      "\n",
      "\n",
      "Mask_1 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_2 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_3 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_4 shape:  torch.Size([4, 2848, 4288])\n",
      "\n",
      "\n",
      "Mask_1 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_2 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_3 shape:  torch.Size([4, 2848, 4288])\n",
      "Mask_4 shape:  torch.Size([4, 2848, 4288])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in valLoader:\n",
    "#     image, label = data\n",
    "#     print(\"Image shape: \", image.shape)\n",
    "#     print(\"Label shape: \", label.shape)\n",
    "    print(\"Mask_1 shape: \", data[0].shape)\n",
    "    print(\"Mask_2 shape: \", data[1].shape)\n",
    "    print(\"Mask_3 shape: \", data[2].shape)\n",
    "    print(\"Mask_4 shape: \", data[3].shape)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51254912",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-fd03872df718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seg_he_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seg_he_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# img2 = cv2.imread('IDRiD_54_HE.tif')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# # os.path.isfile('/mnt/sda/haal02-data/IDRID/A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/2. Haemorrhages/IDRiD_42_HE.tif')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "dir1 = '/mnt/sda/haal02-data/IDRID/A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/2. Haemorrhages'\n",
    "\n",
    "dir2 = '/mnt/sda/haal02-data/IDRID/'\n",
    "\n",
    "train_data.image_df\n",
    "img = cv2.imread(os.path.join(data_dir, train_data.image_df['seg_he_path'][0]))\n",
    "os.path.join(data_dir, train_data.image_df['seg_he_path'][0])\n",
    "img.shape\n",
    "# img2 = cv2.imread('IDRiD_54_HE.tif')\n",
    "# # os.path.isfile('/mnt/sda/haal02-data/IDRID/A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/2. Haemorrhages/IDRiD_42_HE.tif')\n",
    "# img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c83d6e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/sda/haal02-data/IDRID/A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/2. Haemorrhages/IDRiD_53_HE.tif\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-70d818c252c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(dir1):\n",
    "    f_path = os.path.join(dir1, file.strip('\\n'))\n",
    "    print(f_path)\n",
    "    img = cv2.imread(os.path.join(dir1, file), cv2.IMREAD_GRAYSCALE)\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e12ab310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir2 = '/mnt/sda/haal02-data/IDRID/'\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "im = Image.open(os.path.join(dir2, 'A. Segmentation/2. All Segmentation Groundtruths/b. Testing Set/3. Hard Exudates/IDRiD_80_EX.tif'))\n",
    "im.show()\n",
    "im = np.array(im)\n",
    "im.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f45772f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if im.ndim =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1874f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def BCEDiceLoss(inputs, targets):\n",
    "    bce = F.binary_cross_entropy(inputs, targets)\n",
    "    inter = (inputs * targets).sum()\n",
    "    eps = 1e-5\n",
    "    dice = (2 * inter + eps) / (inputs.sum() + targets.sum() + eps)\n",
    "    return bce + 1 - dice\n",
    "\n",
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        if isinstance(target, tuple):\n",
    "            target = target[0]\n",
    "        if inputs.shape[1] == 5:\n",
    "            loss1 = BCEDiceLoss(inputs[:, 0, :, :], target)\n",
    "            loss2 = BCEDiceLoss(inputs[:, 1, :, :], target)\n",
    "            loss3 = BCEDiceLoss(inputs[:, 2, :, :], target)\n",
    "            loss4 = BCEDiceLoss(inputs[:, 3, :, :], target)\n",
    "            loss5 = BCEDiceLoss(inputs[:, 4, :, :], target)\n",
    "            return loss1 + loss2 + loss3 + loss4 + loss5\n",
    "        elif inputs.shape[1] == 1:\n",
    "            #print(inputs.shape)\n",
    "            loss = BCEDiceLoss(inputs[:, 0, :, :], target)\n",
    "            return loss\n",
    "\n",
    "\n",
    "class FLoss(nn.Module):\n",
    "    def __init__(self, beta=0.3, log_like=False):\n",
    "        super(FLoss, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.log_like = log_like\n",
    "\n",
    "    def _compute_loss(self, prediction, target):\n",
    "        EPS = 1e-10\n",
    "        N = prediction.size(0)\n",
    "        TP = (prediction * target).view(N, -1).sum(dim=1)\n",
    "        H = self.beta * target.view(N, -1).sum(dim=1) + prediction.view(N, -1).sum(dim=1)\n",
    "        fmeasure = (1 + self.beta) * TP / (H + EPS)\n",
    "        if self.log_like:\n",
    "            loss = -torch.log(fmeasure)\n",
    "        else:\n",
    "            loss  = 1 - fmeasure\n",
    "        return loss.mean()\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        loss1 = self._compute_loss(inputs[:, 0, :, :], target)\n",
    "        loss2 = self._compute_loss(inputs[:, 1, :, :], target)\n",
    "        loss3 = self._compute_loss(inputs[:, 2, :, :], target)\n",
    "        loss4 = self._compute_loss(inputs[:, 3, :, :], target)\n",
    "        loss5 = self._compute_loss(inputs[:, 4, :, :], target)\n",
    "        return 1.0*loss1 + 1.0*loss2 + 1.0*loss3 + 1.0*loss4 + 1.0*loss5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ab9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val(args, val_loader, model, criterion):\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    sal_eval_val = IoUEval()\n",
    "    epoch_loss = []\n",
    "    total_batches = len(val_loader)\n",
    "    for iter, (input, target) in enumerate(val_loader):\n",
    "        start_time = time.time()\n",
    "\n",
    "        if args.gpu:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "        input_var = torch.autograd.Variable(input)\n",
    "        target_var = torch.autograd.Variable(target).float()\n",
    "\n",
    "        # run the mdoel\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "        #torch.cuda.synchronize()\n",
    "        time_taken = time.time() - start_time\n",
    "\n",
    "        epoch_loss.append(loss.data.item())\n",
    "\n",
    "        # compute the confusion matrix\n",
    "        if args.gpu and torch.cuda.device_count() > 1:\n",
    "            output = gather(output, 0, dim=0)\n",
    "        sal_eval_val.add_batch(output[:, 0, :, :],  target_var)\n",
    "        if iter % 50 == 0 or iter == len(val_loader) - 1:\n",
    "            print('[%d/%d] loss: %.3f time: %.3f' % (iter, total_batches, loss.data.item(), time_taken))\n",
    "\n",
    "    average_epoch_loss_val = sum(epoch_loss) / len(epoch_loss)\n",
    "    IoU, MAE = sal_eval_val.get_metric()\n",
    "    \n",
    "    auc_roc_score = sal_eval_val.get_auc_roc()\n",
    "    \n",
    "    return average_epoch_loss_val, IoU, MAE, auc_roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec50633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_batches 54\n"
     ]
    }
   ],
   "source": [
    "NORMALISE_PARAMS = [np.array([0.406, 0.456, 0.485], dtype=np.float32).reshape((1, 1, 3)), # MEAN\n",
    "                        np.array([0.225, 0.224, 0.229], dtype=np.float32).reshape((1, 1, 3))] # STD\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "data_dir = './data/IDRID'\n",
    "num_workers = 8\n",
    "batch_size = 1\n",
    "\n",
    "# compose the data with transforms\n",
    "trainDataset_main = myTransforms.Compose([\n",
    "    myTransforms.Normalize(*NORMALISE_PARAMS),\n",
    "    myTransforms.Scale(width, height),\n",
    "    myTransforms.RandomCropResize(int(7./224.*width)),\n",
    "    myTransforms.RandomFlip(),\n",
    "    #myTransforms.GaussianNoise(),\n",
    "    myTransforms.ToTensor()\n",
    "])\n",
    "\n",
    "trainDataset_scale1 = myTransforms.Compose([\n",
    "#         myTransforms.Normalize(*NORMALISE_PARAMS),\n",
    "    #myTransforms.Scale(512, 512),\n",
    "    myTransforms.Scale(352, 352),\n",
    "#         myTransforms.RandomCropResize(int(7./224.*args.width)),\n",
    "#         myTransforms.RandomFlip(),\n",
    "    myTransforms.ToTensor()\n",
    "])\n",
    "trainDataset_scale2 = myTransforms.Compose([\n",
    "    myTransforms.Normalize(*NORMALISE_PARAMS),\n",
    "    #myTransforms.Scale(1024, 1024),\n",
    "    myTransforms.Scale(448, 448),\n",
    "    myTransforms.RandomCropResize(int(7./224.*width)),\n",
    "    myTransforms.RandomFlip(),\n",
    "    myTransforms.ToTensor()\n",
    "])\n",
    "\n",
    "valDataset = myTransforms.Compose([\n",
    "    myTransforms.Normalize(*NORMALISE_PARAMS),\n",
    "    myTransforms.Scale(width, height),\n",
    "    myTransforms.ToTensor()\n",
    "])\n",
    "\n",
    "# since we training from scratch, we create data loaders at different scales\n",
    "# so that we can generate more augmented data and prevent the network from overfitting\n",
    "trainLoader_main = torch.utils.data.DataLoader(\n",
    "    Dataset(data_dir, 'train', transform=trainDataset_main),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=False, drop_last=True)\n",
    "\n",
    "valLoader = torch.utils.data.DataLoader(\n",
    "    Dataset(data_dir, 'test', transform=valDataset),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=False, drop_last=True)\n",
    "\n",
    "max_batches = len(trainLoader_main) #+ len(trainLoader_scale1) + len(trainLoader_scale2)\n",
    "print('max_batches {}'.format(max_batches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c50cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d5fa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JCS(\n",
       "  (vgg16): VGG16BN(\n",
       "    (conv1_1): ConvBNReLU(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(64)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv1_2): ConvBNReLU(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(64)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2_1): ConvBNReLU(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(128)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2_2): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(128)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv3_1): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(256)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv3_2): ConvBNReLU(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(256)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv3_3): ConvBNReLU(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(256)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv4_1): ConvBNReLU(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(512)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv4_2): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(512)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv4_3): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(512)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv5_1): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(512)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5_2): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(512)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5_3): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): FrozenBatchNorm2d(512)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (gpd): GPD(\n",
       "    (expand_conv): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (reduce_conv): ConvBNReLU(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (end_conv): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (se_block): SEBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=1024, bias=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (dilation_convs): ModuleList(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(9, 9), dilation=(9, 9))\n",
       "    )\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (act2): ReLU(inplace=True)\n",
       "  )\n",
       "  (gpd1): GPD(\n",
       "    (expand_conv): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (reduce_conv): ConvBNReLU(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (end_conv): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (se_block): SEBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=1024, bias=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (dilation_convs): ModuleList(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "    )\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (act2): ReLU(inplace=True)\n",
       "  )\n",
       "  (fpn): ImprovedDecoder(\n",
       "    (inners_a): ModuleList(\n",
       "      (0): ConvBNReLU(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvBNReLU(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvBNReLU(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (inners_b): ModuleList(\n",
       "      (0): ConvBNReLU(\n",
       "        (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvBNReLU(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fuse): ModuleList(\n",
       "      (0): FuseModule(\n",
       "        (se1): SEBlock(\n",
       "          (linear1): Linear(in_features=64, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=64, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv1): ConvBNReLU(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se2): SEBlock(\n",
       "          (linear1): Linear(in_features=96, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=96, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (reduce_conv): ConvBNReLU(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvBNReLU(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): FuseModule(\n",
       "        (se1): SEBlock(\n",
       "          (linear1): Linear(in_features=128, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=128, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv1): ConvBNReLU(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se2): SEBlock(\n",
       "          (linear1): Linear(in_features=192, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=192, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (reduce_conv): ConvBNReLU(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvBNReLU(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): FuseModule(\n",
       "        (se1): SEBlock(\n",
       "          (linear1): Linear(in_features=256, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=256, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv1): ConvBNReLU(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se2): SEBlock(\n",
       "          (linear1): Linear(in_features=384, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=384, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (reduce_conv): ConvBNReLU(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvBNReLU(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): FuseModule(\n",
       "        (se1): SEBlock(\n",
       "          (linear1): Linear(in_features=512, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=512, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv1): ConvBNReLU(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se2): SEBlock(\n",
       "          (linear1): Linear(in_features=768, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=768, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (reduce_conv): ConvBNReLU(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvBNReLU(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): FuseModule(\n",
       "        (se1): SEBlock(\n",
       "          (linear1): Linear(in_features=512, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=512, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv1): ConvBNReLU(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se2): SEBlock(\n",
       "          (linear1): Linear(in_features=768, out_features=1, bias=True)\n",
       "          (linear2): Linear(in_features=1, out_features=768, bias=True)\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (reduce_conv): ConvBNReLU(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvBNReLU(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cls2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cls3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cls4): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cls5): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = net.JCS()\n",
    "checkpoint_path = './snapshots/18_08/single_pretrained_full_seg_idrid_full_sg_mean_60epoch/checkpoint.pth.tar'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4b5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vals = []\n",
    "sal_eval_val = IoUEval()\n",
    "for iter, (input, target) in enumerate(valLoader):\n",
    "    torch.cuda.empty_cache()\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    input = input.cuda()\n",
    "    target = target.cuda()\n",
    "    input_var = torch.autograd.Variable(input)\n",
    "    target_var = torch.autograd.Variable(target).float()\n",
    "\n",
    "    # run the mdoel\n",
    "    output = model(input_var)\n",
    "    output_vals.append(output[:,0,:,:].detach().cpu().numpy())\n",
    "#     sal_eval_val.add_batch(output[:, 0, :, :],  target_var)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0042401a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vals[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f8c4a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96140996384955"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support, average_precision_score, roc_auc_score\n",
    "import numpy as np\n",
    "data_len = len(valLoader.dataset)\n",
    "tot_auc_pr = 0.0\n",
    "for iter, (input, target) in enumerate(valLoader):\n",
    "    target = target.flatten().numpy()\n",
    "    out = output_vals[iter].flatten()\n",
    "    auc_pr = roc_auc_score(target, out)\n",
    "    tot_auc_pr += auc_pr\n",
    "#     print(\"AUC PR: \", auc_pr)\n",
    "tot_auc_pr/data_len"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
